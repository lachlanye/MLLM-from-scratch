{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc04a978",
   "metadata": {},
   "source": [
    "# ViT CIFAR-10（Colab A100 完整流程）\n",
    "本 Notebook 依照预设的 8 个章节，在 Colab A100 上完成 Vision Transformer 的安装、训练、评估、推理与 Git 同步。请按顺序执行每个单元。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eaeaad4",
   "metadata": {},
   "source": [
    "## 1. 环境准备\n",
    "- 选择 `Runtime → Change runtime type → GPU → A100`.\n",
    "- 运行下方单元安装依赖与同步代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61d9983d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov 26 09:21:36 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   29C    P0             43W /  400W |       0MiB /  40960MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.4.2 which is incompatible.\n",
      "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "tensorflow 2.19.0 requires tensorboard~=2.19.0, but you have tensorboard 2.17.0 which is incompatible.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.4.2 which is incompatible.\n",
      "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n",
      "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "tensorflow 2.19.0 requires tensorboard~=2.19.0, but you have tensorboard 2.17.0 which is incompatible.\n",
      "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
      "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "!pip install --quiet --upgrade pip\n",
    "# 强制安装 numpy<2 以兼容 torch 2.2.x\n",
    "!pip install --quiet \"numpy<2\"\n",
    "!pip install --quiet torch==2.2.2+cu121 torchvision==0.17.2+cu121 torchaudio==2.2.2 --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install --quiet timm==0.9.16 torchmetrics==1.3.2 tensorboard==2.17.0 scikit-learn==1.4.2 einops==0.7.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfeae36",
   "metadata": {},
   "source": [
    "## 2. Git 设置与仓库同步\n",
    "- 将个人访问令牌保存到 `GITHUB_TOKEN` 变量后执行下方单元。\n",
    "- 每次进入 Colab 需重新克隆仓库。\n",
    "- 提醒：如果代码有更改，记得先push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db239f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/MLLM-from-scratch/MLLM-from-scratch\n"
     ]
    }
   ],
   "source": [
    "import getpass, os, subprocess\n",
    "REPO_URL = \"https://github.com/lachlanye/MLLM-from-scratch.git\"  \n",
    "if \"GITHUB_TOKEN\" not in os.environ:\n",
    "    # 建议使用 Colab 的 Secrets 功能存储 Token，或者在运行时手动输入\n",
    "    print(\"请输入 GitHub Token:\")\n",
    "    os.environ[\"GITHUB_TOKEN\"] = getpass.getpass()\n",
    "\n",
    "repo_name = REPO_URL.split(\"/\")[-1].replace(\".git\", \"\")\n",
    "if not os.path.exists(repo_name):\n",
    "    subprocess.run([\"git\", \"clone\", f\"https://{os.environ['GITHUB_TOKEN']}@\" + REPO_URL.split(\"https://\")[-1]], check=True)\n",
    "%cd $repo_name\n",
    "!git config user.name \"lachlanye\"\n",
    "!git config user.email \"colab@example.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a6a7c5",
   "metadata": {},
   "source": [
    "## 3. 数据集准备\n",
    "此项目使用 `datasets/cifar10.py` 中的封装，默认会在 `data/` 目录下载 CIFAR-10。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb5143f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_reconstruct: First argument must be a sub-type of ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-3455354833.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexec_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcifar_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcifar_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_cifar10_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/MLLM-from-scratch/MLLM-from-scratch/datasets/cifar10.py\u001b[0m in \u001b[0;36mbuild_cifar10_datasets\u001b[0;34m(data_dir, train_transform, test_transform, download)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;34m\"\"\"Utility that returns train/test datasets with optional transforms.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     train_dataset = CIFAR10Dataset(\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/MLLM-from-scratch/MLLM-from-scratch/datasets/cifar10.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, train, transform, download)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcifar10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCIFAR10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcifar10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                 \u001b[0mentry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"latin1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"labels\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: _reconstruct: First argument must be a sub-type of ndarray"
     ]
    }
   ],
   "source": [
    "import importlib.util\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "data_dir = Path(\"data\")\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# 直接从文件路径加载模块，绕过包缓存\n",
    "file_path = \"datasets/cifar10.py\"\n",
    "spec = importlib.util.spec_from_file_location(\"datasets.cifar10\", file_path)\n",
    "cifar_module = importlib.util.module_from_spec(spec)\n",
    "sys.modules[\"datasets.cifar10\"] = cifar_module\n",
    "spec.loader.exec_module(cifar_module)\n",
    "\n",
    "train_dataset, test_dataset = cifar_module.build_cifar10_datasets(data_dir=str(data_dir))\n",
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f654d0c3",
   "metadata": {},
   "source": [
    "## 4. 训练参数与配置\n",
    "可直接修改 `configs/vit_config.yaml`，或在下方通过 `omegaconf` 动态更新。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "705ea7e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_params': {'dataset': 'CIFAR10',\n",
       "  'data_dir': './data/cifar10',\n",
       "  'img_size': 32,\n",
       "  'patch_size': 4,\n",
       "  'in_channels': 3,\n",
       "  'num_classes': 10,\n",
       "  'class_names': ['plane',\n",
       "   'car',\n",
       "   'bird',\n",
       "   'cat',\n",
       "   'deer',\n",
       "   'dog',\n",
       "   'frog',\n",
       "   'horse',\n",
       "   'ship',\n",
       "   'truck'],\n",
       "  'mean': [0.4914, 0.4822, 0.4465],\n",
       "  'std': [0.247, 0.2435, 0.2616]},\n",
       " 'model_params': {'d_model': 512,\n",
       "  'num_layers': 6,\n",
       "  'n_heads': 8,\n",
       "  'd_ff': 2048,\n",
       "  'dropout': 0.1},\n",
       " 'training_params': {'device': 'cuda',\n",
       "  'num_epochs': 50,\n",
       "  'batch_size': 128,\n",
       "  'learning_rate': 0.001,\n",
       "  'weight_decay': 0.0001,\n",
       "  'eval_interval': 5,\n",
       "  'model_save_path': './checkpoints/vit_cifar10.pth'},\n",
       " 'prediction_params': {'image_source': ''}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import yaml\n",
    "from copy import deepcopy\n",
    "config_path = Path(\"configs/vit_config.yaml\")\n",
    "with open(config_path) as f:\n",
    "    vit_cfg = yaml.safe_load(f)\n",
    "display(vit_cfg)\n",
    "# 示例：在 Notebook 中快速修改批大小\n",
    "# vit_cfg_overrides = deepcopy(vit_cfg)\n",
    "# vit_cfg_overrides[\"training\"][\"batch_size\"] = 256\n",
    "# print(\"Override batch size -> 256\")\n",
    "# with open(\"/tmp/vit_config_colab.yaml\", \"w\") as f:\n",
    "#     yaml.safe_dump(vit_cfg_overrides, f)\n",
    "# print(\"已写入 /tmp/vit_config_colab.yaml，可用于训练脚本\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f914e355",
   "metadata": {},
   "source": [
    "## 5. 开始训练\n",
    "默认脚本位于 `vision_transformer/train_vit.py`，训练日志写入 `runs/vit_cifar10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1540c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m vision_transformer.train_vit --config configs/vit_config.yaml --device cuda --log_dir runs/vit_cifar10\n",
    "!ls -R runs/vit_cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5a188e",
   "metadata": {},
   "source": [
    "## 6. 评估与可视化\n",
    "使用 `torchmetrics` 计算准确率，并读取 TensorBoard 日志。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a918a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "from torchvision import transforms\n",
    "from vision_transformer.vit import VisionTransformer\n",
    "from configs import config_parser\n",
    "cfg = config_parser.load_config(\"configs/vit_config.yaml\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "state_dict = torch.load(cfg[\"inference\"][\"weights_path\"], map_location=device)\n",
    "model = VisionTransformer(cfg[\"model\"]).to(device)\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "transform = transforms.Compose([transforms.Resize(224), transforms.ToTensor(), transforms.Normalize(mean=cfg[\"data\"][\"mean\"], std=cfg[\"data\"][\"std\"])])\n",
    "test_dataset.transform = transform\n",
    "loader = DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=2)\n",
    "metric = MulticlassAccuracy(num_classes=10).to(device)\n",
    "with torch.no_grad():\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        preds = model(images)\n",
    "        metric.update(preds, labels)\n",
    "print(\"Test Top-1 Acc:\", metric.compute().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12902279",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs/vit_cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcdf1eb",
   "metadata": {},
   "source": [
    "## 7. 推理与可视化预测\n",
    "调用 `vision_transformer/predict_vit.py` 或直接在 Notebook 中推理若干图像。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407a1a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m vision_transformer.predict_vit --config configs/vit_config.yaml --weights_path runs/vit_cifar10/best.ckpt --samples 8\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "classes = cfg[\"data\"][\"classes\"]\n",
    "indices = random.sample(range(len(test_dataset)), 6)\n",
    "fig, axes = plt.subplots(2, 3, figsize=(10, 6))\n",
    "model.eval()\n",
    "for ax, idx in zip(axes.flatten(), indices):\n",
    "    image, label = test_dataset[idx]\n",
    "    with torch.no_grad():\n",
    "        pred = model(image.unsqueeze(0).to(device))\n",
    "        pred_idx = pred.argmax(dim=1).item()\n",
    "    ax.imshow(image.permute(1, 2, 0).cpu().numpy() * 0.5 + 0.5)\n",
    "    ax.set_title(f\"GT: {classes[label]}, Pred: {classes[pred_idx]}\")\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b1cd5d",
   "metadata": {},
   "source": [
    "## 8. 保存结果并推送\n",
    "将训练好的权重、日志与 Notebook 推送回远程仓库。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3765bd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git status\n",
    "!git add runs/vit_cifar10 notebooks/vit_cifar10_colab.ipynb configs/vit_config.yaml\n",
    "!git commit -m \"Update ViT Colab run\" || echo \"Nothing to commit\"\n",
    "!git push origin main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723089d9",
   "metadata": {},
   "source": [
    "---\n",
    "**提示**\n",
    "- 如需重新初始化环境，执行 `Runtime → Factory reset runtime` 后从第 1 节开始。\n",
    "- 若想只拉取最新改动，可在第 2 节中改为 `git pull origin main`。\n",
    "- 建议在推送前下载 `runs/` 与 `best.ckpt` 以备份模型。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
