{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ed2c7cd",
   "metadata": {},
   "source": [
    "## 1. 环境准备\n",
    "- 建议使用 GPU 运行时 (Runtime -> Change runtime type -> GPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "795a8ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Nov 27 04:52:26 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   40C    P0             46W /  400W |       0MiB /  40960MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "!pip install --quiet --upgrade pip\n",
    "# 强制安装 numpy<2 以兼容 torch 2.2.x\n",
    "!pip install --quiet \"numpy<2\"\n",
    "!pip install --quiet torch==2.2.2+cu121 torchvision==0.17.2+cu121 torchaudio==2.2.2 --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install --quiet tqdm omegaconf matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177584f7",
   "metadata": {},
   "source": [
    "## 2. Git 设置与仓库同步"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e171213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already in MLLM-from-scratch directory.\n",
      "From https://github.com/lachlanye/MLLM-from-scratch\n",
      " * branch            master     -> FETCH_HEAD\n",
      "Already up to date.\n",
      "From https://github.com/lachlanye/MLLM-from-scratch\n",
      " * branch            master     -> FETCH_HEAD\n",
      "Already up to date.\n"
     ]
    }
   ],
   "source": [
    "import getpass, os, subprocess\n",
    "\n",
    "REPO_URL = \"https://github.com/lachlanye/MLLM-from-scratch.git\"\n",
    "repo_name = REPO_URL.split(\"/\")[-1].replace(\".git\", \"\")\n",
    "\n",
    "# 1. 防止嵌套目录：检查当前是否已经在仓库目录中\n",
    "if os.getcwd().endswith(repo_name):\n",
    "    print(f\"Already in {repo_name} directory.\")\n",
    "else:\n",
    "    # 2. 如果不在，检查是否存在，不存在则克隆\n",
    "    if not os.path.exists(repo_name):\n",
    "        print(f\"Cloning {repo_name}...\")\n",
    "        # 请确保设置了 GITHUB_TOKEN\n",
    "        os.environ[\"GITHUB_TOKEN\"] = \"YOUR_TOKEN\"\n",
    "        subprocess.run([\"git\", \"clone\", f\"https://{os.environ['GITHUB_TOKEN']}@\" + REPO_URL.split(\"https://\")[-1]], check=True)\n",
    "    \n",
    "    # 3. 进入目录\n",
    "    %cd $repo_name\n",
    "\n",
    "# 4. 配置 Git\n",
    "!git config user.name \"lachlanye\"\n",
    "!git config user.email \"colab@example.com\"\n",
    "\n",
    "# 5. 拉取代码 (使用 master 分支)\n",
    "!git pull origin master"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fb94ad",
   "metadata": {},
   "source": [
    "## 3. 数据集准备\n",
    "加载 Tiny Shakespeare 数据集并查看部分数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ef63962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists at data/tinyshakespeare/input.txt, skipping download.\n",
      "Found existing vocabulary at data/tinyshakespeare/vocab.json. Loading...\n",
      "Vocabulary loaded from data/tinyshakespeare/vocab.json\n",
      "Encoding the entire corpus into a single sequence...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists at data/tinyshakespeare/input.txt, skipping download.\n",
      "Found existing vocabulary at data/tinyshakespeare/vocab.json. Loading...\n",
      "Vocabulary loaded from data/tinyshakespeare/vocab.json\n",
      "Encoding the entire corpus into a single sequence...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'ellipsis' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-4180886627.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 初始化数据集 (会自动下载)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTinyShakespeareDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Vocab size: {dataset.vocab_size}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Dataset length: {len(dataset)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/MLLM-from-scratch/MLLM-from-scratch/datasets/tinyshakespeare.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, block_size, download)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Encoding the entire corpus into a single sequence...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Corpus successfully encoded. Total characters (tokens): {len(self.data)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'ellipsis' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "from datasets.tinyshakespeare import TinyShakespeareDataset\n",
    "import torch\n",
    "\n",
    "# 初始化数据集 (会自动下载)\n",
    "dataset = TinyShakespeareDataset(root=\"data\", download=True)\n",
    "print(f\"Vocab size: {dataset.vocab_size}\")\n",
    "print(f\"Dataset length: {len(dataset)}\")\n",
    "\n",
    "# 查看前 200 个字符\n",
    "print(\"\\n--- Data Sample ---\")\n",
    "print(dataset.tokenizer.decode(dataset.data[:200].tolist()))\n",
    "print(\"-------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fc1840",
   "metadata": {},
   "source": [
    "## 4. 训练配置\n",
    "查看当前的训练配置 `configs/llm_config.yaml`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cda5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "config_path = Path(\"configs/llm_config.yaml\")\n",
    "with open(config_path) as f:\n",
    "    config = yaml.safe_load(f)\n",
    "    \n",
    "# 可以在这里动态修改配置，例如增加 epoch\n",
    "# config['training_params']['num_epochs'] = 5\n",
    "# with open(config_path, 'w') as f:\n",
    "#     yaml.dump(config, f)\n",
    "\n",
    "print(yaml.dump(config))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58f550b",
   "metadata": {},
   "source": [
    "## 5. 开始训练\n",
    "运行 `language_model/train_llm.py`。我们将输出重定向到日志文件以便后续绘图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c4f125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确保保存目录存在\n",
    "!mkdir -p checkpoints\n",
    "# 运行训练并将输出同时显示在控制台和保存到 training.log\n",
    "!python -m language_model.train_llm | tee training.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57ca18c",
   "metadata": {},
   "source": [
    "## 6. 训练过程可视化 (Loss Curve)\n",
    "解析 `training.log` 并绘制训练和验证 Loss 曲线。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e19a72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "epochs = []\n",
    "\n",
    "# 解析日志文件\n",
    "with open(\"training.log\", \"r\") as f:\n",
    "    for line in f:\n",
    "        # 匹配格式: Epoch 1/10 Summary | Train Loss: 2.5000 | Val Loss: 2.4000\n",
    "        match = re.search(r\"Epoch (\\d+)/\\d+ Summary \\| Train Loss: ([\\d\\.]+) \\| Val Loss: ([\\d\\.]+)\", line)\n",
    "        if match:\n",
    "            epochs.append(int(match.group(1)))\n",
    "            train_losses.append(float(match.group(2)))\n",
    "            val_losses.append(float(match.group(3)))\n",
    "\n",
    "if not epochs:\n",
    "    print(\"未找到训练日志数据，请检查训练是否成功完成。\")\n",
    "else:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epochs, train_losses, label='Train Loss', marker='o')\n",
    "    plt.plot(epochs, val_losses, label='Validation Loss', marker='s')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss over Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d4fde0",
   "metadata": {},
   "source": [
    "## 7. 文本生成展示\n",
    "使用训练好的模型生成莎士比亚风格的文本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b7d739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 样本 1\n",
    "!python -m language_model.generate_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f949e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 样本 2 (修改 configs/llm_config.yaml 中的 start_context 来生成不同的文本)\n",
    "import yaml\n",
    "\n",
    "# 读取配置\n",
    "with open(\"configs/llm_config.yaml\", 'r') as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "# 修改起始文本\n",
    "cfg['generation_params']['start_context'] = \"To be, or not to be\"\n",
    "\n",
    "# 写入临时配置\n",
    "with open(\"configs/llm_config_sample2.yaml\", 'w') as f:\n",
    "    yaml.dump(cfg, f)\n",
    "\n",
    "# 使用新配置生成\n",
    "# 注意：generate_text.py 默认读取 configs/llm_config.yaml，我们需要修改代码或覆盖文件\n",
    "# 这里简单起见，我们直接覆盖原配置文件，生成后再改回来 (或者修改 generate_text.py 接受参数)\n",
    "# 为了演示，我们直接覆盖\n",
    "with open(\"configs/llm_config.yaml\", 'w') as f:\n",
    "    yaml.dump(cfg, f)\n",
    "\n",
    "print(\"--- Sample 2: 'To be, or not to be' ---\")\n",
    "!python -m language_model.generate_text\n",
    "\n",
    "# 恢复配置 (可选)\n",
    "cfg['generation_params']['start_context'] = \"You are all resolved\"\n",
    "with open(\"configs/llm_config.yaml\", 'w') as f:\n",
    "    yaml.dump(cfg, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3989d7e6",
   "metadata": {},
   "source": [
    "## 8. 保存结果\n",
    "将训练好的模型和日志推送到 GitHub。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c895ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git status\n",
    "!git add -f checkpoints/llm_tinyshakespeare.pth training.log\n",
    "!git commit -m \"Add LLM training results and logs\" || echo \"Nothing to commit\"\n",
    "!git push origin master"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
